/*
 * Licensed to the Apache Software Foundation (ASF) under one or more
 * contributor license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright ownership.
 * The ASF licenses this file to You under the Apache License, Version 2.0
 * (the "License"); you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package edu.uchicago.mpcs53013.TwitterFeed;
import scala.Tuple2;
import twitter4j.Status;

import com.google.common.collect.Lists;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.StorageLevels;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.twitter.TwitterUtils;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.IOException;
import java.util.Arrays;
import java.util.Properties;
import java.util.regex.Pattern;

import org.apache.spark.Logging;
import org.apache.log4j.*;
// Based off http://ampcamp.berkeley.edu/big-data-mini-course/realtime-processing-with-spark-streaming.html
// and https://github.com/pwendell/spark-twitter-collection/blob/master/TwitterUtils.scala
public final class TweetCountByCountry {
	static void configureTwitterCredentials() throws IOException {
		Properties properties = new Properties();
		FileInputStream in = new FileInputStream("twitter.properties");
		properties.load(in);
		in.close();	
		Logger.getLogger("spark").warn("Configuring Twitter OAuth");
		System.setProperty("twitter4j.oauth.consumerKey", properties.getProperty("consumerKey"));
		System.setProperty("twitter4j.oauth.consumerSecret", properties.getProperty("consumerSecret"));
		System.setProperty("twitter4j.oauth.accessToken", properties.getProperty("accessToken"));
		System.setProperty("twitter4j.oauth.accessTokenSecret", properties.getProperty("accessTokenSecret"));
	}

	private static final Pattern SPACE = Pattern.compile(" ");
	public static void main(String[] args) throws IOException {
		configureTwitterCredentials();
		boolean log4jInitialized = Logger.getLogger("spark").getAllAppenders().hasMoreElements();
		if (!log4jInitialized) {
			// We first log something to initialize Spark's default logging, then we override the
			// logging level.
			Logger.getLogger("spark").info("Setting log level to [WARN] for streaming example." +
					" To override add a custom log4j.properties to the classpath.");
			Logger.getLogger("spark").setLevel(Level.WARN);
			Logger.getRootLogger().setLevel(Level.WARN);
		}		
		// Create the context with a 1 second batch size
		SparkConf sparkConf 
		= new SparkConf().setAppName("TwitterSpark");
		JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(1000));
		// Create a JavaReceiverInputDStream on target ip:port and count the
		// words in input stream of \n delimited text (eg. generated by 'nc')
		// Note that no duplication in storage level only for running locally.
		// Replication necessary in distributed scenario for fault tolerance.
		JavaReceiverInputDStream<Status> tweets = TwitterUtils.createStream(ssc);
		// Think of each of the following streams as like an alias in a Pig pipeline
		JavaDStream<String> locations = tweets.map(
				new Function<Status, String>() {
					public String call(Status status) { 
						if(status.getPlace() != null){
							return status.getPlace().getCountry();
						}
						return "no country given"; }
				}
				);

		// FlatMapFunction breaks one row into several just like FLATTEN in Pig
		// and EXPLODE in Hive
//		JavaDStream<String> words = locations.flatMap(
//				new FlatMapFunction<String, String>() {
//					public Iterable<String> call(String in) {
//						return Arrays.asList(in.split(" "));
//					}
//				}
//				);

//		JavaDStream<String> hashTags = words.filter(
//				new Function<String, Boolean>() {
//					public Boolean call(String word) { return word.startsWith("#"); }
//				}
//				);

		JavaPairDStream<String, Integer> tuples = locations.mapToPair(
				new PairFunction<String, String, Integer>() {
					public Tuple2<String, Integer> call(String in) {
						return new Tuple2<String, Integer>(in, 1);
					}
				}
				);

		JavaPairDStream<String, Integer> counts = tuples.reduceByKeyAndWindow(
				new Function2<Integer, Integer, Integer>() {
					public Integer call(Integer i1, Integer i2) { return i1 + i2; }
				},
				new Function2<Integer, Integer, Integer>() {
					public Integer call(Integer i1, Integer i2) { return i1 - i2; }
				},
				new Duration(60 * 5 * 1000),
				new Duration(1 * 1000)
				);		

		JavaPairDStream<Integer, String> swappedCounts = counts.mapToPair(
				new PairFunction<Tuple2<String, Integer>, Integer, String>() {
					public Tuple2<Integer, String> call(Tuple2<String, Integer> in) {
						return in.swap();
					}
				}
				);

		JavaPairDStream<Integer, String> sortedCounts = swappedCounts.transformToPair(
				new Function<JavaPairRDD<Integer, String>, JavaPairRDD<Integer, String>>() {
					public JavaPairRDD<Integer, String> call(JavaPairRDD<Integer, String> in) throws Exception {
						return in.sortByKey(false);
					}
				});

		sortedCounts.foreach(
				new Function<JavaPairRDD<Integer, String>, Void> () {
					public Void call(JavaPairRDD<Integer, String> rdd) {
						String out = "\nCountries With Most Tweets:\n";
						for (Tuple2<Integer, String> t: rdd.take(10)) {
							out = out + t.toString() + "\n";
						}
						System.out.println(out);
						return null;
					}
				}
				);		// Just like with Pig, the action occurs once you output the final alias
		counts.print();
		ssc.checkpoint("/tmp");
		ssc.start();
		ssc.awaitTermination();
	}
}
